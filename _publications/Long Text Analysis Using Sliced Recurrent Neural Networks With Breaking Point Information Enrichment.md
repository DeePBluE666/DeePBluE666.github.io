---
title: "ICASSP2019： Long Text Analysis Using Sliced Recurrent Neural Networks With Breaking Point Information Enrichment"
collection: publications
permalink: /publication/Long Text Analysis Using Sliced Recurrent Neural Networks With Breaking Point Information Enrichment
excerpt: '
**Brief Introduction** : This paper is about long text classification problem and accepted by ICASSP2019. In this paper, based on SRNN, we propose a breaking point information 
enrichment mechanism to strengthen dependencies between sliced subsequences without hindering parallelization. 


**Authors** : **Bo Li**^‚ Zehua Cheng^‚ Zhenghua Xu‚ Wei Ye‚ Thomas Lukasiewicz and Shikun Zhang. (^indicates co-first author)


**Place** : Brighton‚ UK


**Date** : May 12th−17th, 2019
'

date: May 12, 2019
venue: 'Proceedings of the 2019 IEEE International Conference on Acoustics‚ Speech and Signal Processing (ICASSP2019)'

---
**Abstrcat**

Sliced recurrent neural networks (SRNNs) are the state-of-the-art effificient solution for long text analysis tasks; however, their slicing operations inevitably result
in long-term dependency loss in lower-level networks and thus limit their accuracy. Therefore, we propose a breaking point information enrichment mechanism to 
strengthen dependencies between sliced subsequences without hindering parallelization. Then, the resulting BPIE-SRNN model is further extended to a bidirectional model,
BPIE-BiSRNN, to utilize the dependency information in not only the previous but also the following contexts. Experiments on four large public real-world datasets 
demonstrate that the BPIE-SRNN and BPIE-BiSRNN models always achieve a much better accuracy than SRNNs and BiSRNNs, while maintaining a superior training effificiency. 


**Paper Download**


[Download paper here](http://deepblue666.github.io/files/Long_Text_Analysis_Using_Sliced_Recurrent_Neural_Networks_With_Breaking_Point_Information_Enrichment.pdf) 


**Code**


[Code Availiable Here](https://github.com/limberc/BPIE-BiSRNN)